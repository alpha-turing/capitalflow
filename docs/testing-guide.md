# CapitalFlow Testing Suite Documentation

## Table of Contents

- [Overview](#overview)
- [Test Infrastructure Setup](#test-infrastructure-setup)
- [Test Categories](#test-categories)
- [Running Tests](#running-tests)
- [Test Architecture](#test-architecture)
- [Key Features](#key-features)
- [Test Data Management](#test-data-management)
- [Mathematical Validation](#mathematical-validation)
- [Known Issues & Workarounds](#known-issues--workarounds)
- [Best Practices](#best-practices)
- [Troubleshooting](#troubleshooting)

---

## Overview

The CapitalFlow testing suite is a comprehensive test framework designed to validate the entire user journey of a financial portfolio management system. It covers authentication, file uploads, transaction parsing, portfolio calculations, and mathematical accuracy validation.

### Current Test Coverage
- **Total Tests**: 79 tests
- **Pass Rate**: 76% (60/79 passing)
- **Test Categories**: 4 main API test suites + infrastructure tests
- **Framework**: pytest with asyncio support
- **Database**: SQLite (in-memory for tests)
- **HTTP Client**: httpx AsyncClient

---

## Test Infrastructure Setup

### Prerequisites

```bash
# Install dependencies
pip install -r requirements.txt

# Core testing dependencies
pip install pytest>=7.4.3 pytest-asyncio>=0.21.1 pytest-cov>=4.1.0 httpx>=0.25.2 faker>=20.1.0
```

### Environment Configuration

The test suite automatically configures the environment:

```python
# Environment setup (automatic)
os.environ.setdefault("ENVIRONMENT", "test")
os.environ["DATABASE_URL"] = "sqlite+aiosqlite:///:memory:"
```

### Database Setup

Tests use an in-memory SQLite database that's created fresh for each test session:

```python
# Location: tests/test_database.py
def create_test_engine(database_url: str = "sqlite+aiosqlite:///:memory:"):
    return create_async_engine(
        database_url,
        poolclass=StaticPool,
        connect_args={"check_same_thread": False},
        echo=False  # Set to True for SQL debugging
    )
```

### Key Test Fixtures

Located in `tests/conftest.py`:

#### Core Infrastructure
- `event_loop`: Session-scoped async event loop
- `test_engine`: SQLite database engine for tests
- `db_session`: Fresh database session per test
- `client`: FastAPI test client with dependency overrides

#### Data Generation
- `sample_user`: Creates unique test users with timestamp-based emails
- `sample_portfolio`: Creates test portfolios
- `sample_instruments`: Creates various financial instruments
- `sample_transactions`: Creates test transactions
- `authenticated_user`: Returns authenticated user with JWT token

#### Mock Services
- `mock_pricing_service`: Mocks external price data APIs
- `mock_fx_service`: Mocks foreign exchange rate services

---

## Test Categories

### 1. Authentication API Tests (`tests/api/test_auth.py`)

**Purpose**: Validate user registration, login, logout, and token management

**Test Classes**:
- `TestUserRegistration`: User signup flows
- `TestUserLogin`: Login/logout functionality  
- `TestTokenValidation`: JWT token handling
- `TestAuthenticationFlow`: End-to-end auth workflows

**Status**: ‚úÖ 15/21 passing

**Key Tests**:
```python
# Registration tests
test_successful_user_registration()
test_duplicate_email_registration()
test_invalid_email_format()

# Login tests  
test_successful_login()
test_invalid_credentials()
test_token_expiration_time()

# Security tests
test_concurrent_registration_same_email()
test_logout_invalidates_token()
```

### 2. Dashboard API Tests (`tests/api/test_dashboard.py`)

**Purpose**: Validate dashboard data aggregation and portfolio summaries

**Test Classes**:
- `TestDashboardAccess`: Access control and permissions
- `TestDashboardData`: Data accuracy and completeness
- `TestDashboardPerformance`: Response times and efficiency

**Status**: ‚úÖ 6/6 passing (100%)

**Key Tests**:
```python
test_dashboard_access_authenticated_user()
test_dashboard_content_structure()
test_dashboard_with_sample_data()
test_dashboard_empty_portfolio()
```

### 3. Upload API Tests (`tests/api/test_uploads.py`)

**Purpose**: Validate file upload, parsing, and transaction import functionality

**Test Classes**:
- `TestVestedCSVUpload`: Vested format CSV parsing
- `TestMultiFileUpload`: Multiple file handling
- `TestUploadErrorHandling`: Error scenarios and edge cases
- `TestTransactionParsingAccuracy`: Data accuracy validation

**Status**: ‚úÖ 20/21 passing (95%)

**Key Features Tested**:
```python
# File format support
test_vested_csv_format_detection()
test_multi_file_upload_success()

# Data parsing accuracy  
test_transaction_import_accuracy()
test_vested_csv_column_mapping()

# Error handling
test_upload_empty_file()
test_upload_corrupted_csv()
test_upload_invalid_portfolio_id()
```

### 4. Mathematical Validation Tests (`tests/api/test_calculations.py`)

**Purpose**: Critical mathematical accuracy validation for financial calculations

**Test Classes**:
- `TestPositionCalculations`: Portfolio position calculations
- `TestPortfolioValuation`: Portfolio value and returns
- `TestTaxLotAccounting`: FIFO/LIFO tax lot management
- `TestCorporateActionsImpact`: Stock splits, dividends
- `TestMultiCurrencyCalculations`: Multi-currency support
- `TestFeeAndChargeCalculations`: Transaction cost accuracy
- `TestCalculationEdgeCases`: Edge cases and boundary conditions
- `TestCalculationConsistency`: Repeatability and reliability

**Status**: üîÑ 17/17 tests created, currently failing due to datetime timezone bug

**Critical Tests**:
```python
# Core position calculations
test_simple_buy_position_calculation()
test_multiple_buy_average_cost()  
test_buy_sell_position_calculation()

# Mathematical precision
test_decimal_precision_in_calculations()
test_very_small_amounts()
test_very_large_amounts()

# Tax lot accounting
test_fifo_tax_lot_calculation()
test_complex_tax_lot_scenario()
```

---

## Running Tests

### Basic Test Commands

```bash
# Run all tests
cd /Users/knandula/work/reaum
python -m pytest tests/ -v

# Run specific test categories
python -m pytest tests/api/test_auth.py -v          # Authentication tests
python -m pytest tests/api/test_dashboard.py -v     # Dashboard tests  
python -m pytest tests/api/test_uploads.py -v       # Upload tests
python -m pytest tests/api/test_calculations.py -v  # Calculation tests

# Run specific test classes
python -m pytest tests/api/test_calculations.py::TestPositionCalculations -v

# Run specific test methods
python -m pytest tests/api/test_calculations.py::TestPositionCalculations::test_simple_buy_position_calculation -v
```

### Advanced Test Options

```bash
# Run with coverage report
python -m pytest tests/ --cov=app --cov-report=term-missing

# Quiet mode (less verbose output)
python -m pytest tests/ -q

# Stop on first failure
python -m pytest tests/ -x

# Show local variables on failures  
python -m pytest tests/ -l

# Rerun only failed tests from last run
python -m pytest tests/ --lf

# Run tests in parallel (if pytest-xdist installed)
python -m pytest tests/ -n auto

# Run with specific markers (if configured)
python -m pytest tests/ -m "not slow"

# Generate HTML coverage report
python -m pytest tests/ --cov=app --cov-report=html
```

### Debugging Tests

```bash
# Enable SQL query logging
# Edit tests/test_database.py and set echo=True

# Run single test with full output
python -m pytest tests/api/test_calculations.py::TestPositionCalculations::test_simple_buy_position_calculation -v -s

# Run with pdb debugger on failures
python -m pytest tests/ --pdb

# Run with detailed traceback
python -m pytest tests/ --tb=long
```

---

## Test Architecture

### Dependency Injection Pattern

The test suite uses FastAPI's dependency injection for clean test isolation:

```python
@pytest_asyncio.fixture
async def client(db_session) -> AsyncGenerator[AsyncClient, None]:
    app = create_application()
    
    # Override database dependency
    app.dependency_overrides[get_db] = lambda: db_session
    
    async with AsyncClient(transport=httpx.ASGITransport(app=app), base_url="http://testserver") as test_client:
        yield test_client
    
    app.dependency_overrides.clear()
```

### Test Database Management

Each test gets a fresh database session:

```python
@pytest_asyncio.fixture(scope="function")
async def db_session(test_engine) -> AsyncSession:
    async_session_maker = async_sessionmaker(
        test_engine, class_=AsyncSession, expire_on_commit=False
    )
    
    async with async_session_maker() as session:
        yield session
        await session.rollback()  # Cleanup after each test
```

### Unique Test Data Generation

Tests use timestamp-based unique identifiers to prevent data conflicts:

```python
# Email generation for unique users
email = f"testuser_{int(time.time())}_{str(uuid.uuid4())[:8]}@example.com"
```

---

## Key Features

### 1. **Mathematical Accuracy Validation**

The test suite includes comprehensive mathematical validation to catch calculation errors:

```python
class TestPositionCalculations:
    async def test_multiple_buy_average_cost(self, authenticated_user, sample_portfolio, client):
        """Test average cost calculation with multiple buy transactions."""
        # Buy 100 shares at $50 = $5,000
        # Buy 200 shares at $60 = $12,000  
        # Buy 100 shares at $40 = $4,000
        # Total: 400 shares at $52.50 average = $21,000 total invested
        
        assert dashboard_data["total_invested"] == 21000.0
```

### 2. **Real CSV File Processing**

Tests validate actual CSV parsing with real-world data formats:

```python
csv_content = """Date,Symbol,Company Name,Transaction Type,Quantity,Price,Total Amount
2024-01-15,AAPL,Apple Inc,BUY,100,150.25,15025.00
2024-01-20,GOOGL,Alphabet Inc,BUY,50,2750.80,137540.00"""
```

### 3. **Authentication Flow Testing**

Complete JWT token lifecycle testing:

```python
@pytest_asyncio.fixture
async def authenticated_user(client: AsyncClient, sample_user: User):
    login_data = {"email": sample_user.email, "password": "testpass123"}
    response = await client.post("/api/v1/auth/login", json=login_data)
    token_data = response.json()
    
    return {
        "user": sample_user,
        "token": token_data["access_token"],
        "headers": {"Authorization": f"Bearer {token_data['access_token']}"}
    }
```

### 4. **Error Scenario Testing**

Comprehensive error handling validation:

```python
async def test_upload_empty_file(self, authenticated_user, sample_portfolio, client):
    empty_file = BytesIO(b"")
    response = await client.post(
        "/api/v1/uploads/",
        files={"files": ("empty.csv", empty_file, "text/csv")}
    )
    assert response.status_code in [400, 422]
```

---

## Test Data Management

### Faker Integration

The test suite uses Faker for generating realistic test data:

```python
fake = Faker()
fake.seed_instance(42)  # For reproducible test data

def generate_user(**overrides):
    defaults = {
        "email": f"user_{int(time.time())}_{str(uuid.uuid4())[:8]}@example.com",
        "full_name": fake.name(),
        "is_active": True,
    }
    return defaults
```

### Sample Data Fixtures

Pre-configured sample data for consistent testing:

```python
@pytest_asyncio.fixture
async def sample_instruments(db_session, instrument_data_generator):
    instrument_configs = [
        {"name": "Reliance Industries", "symbol": "RELIANCE", "asset_class": AssetClass.EQUITY},
        {"name": "HDFC Bank", "symbol": "HDFCBANK", "asset_class": AssetClass.EQUITY},
        {"name": "SBI Bluechip Fund", "symbol": "SBI_BC", "asset_class": AssetClass.MUTUAL_FUND},
    ]
    # ... create instruments
```

---

## Mathematical Validation

### Purpose

The calculation tests are designed to catch critical mathematical errors in financial calculations. **This is the most important part of the test suite** as calculation errors can lead to incorrect investment decisions and tax liabilities.

### Current Status: Successfully Identifying Bugs! üéØ

The mathematical validation tests are **working as designed** - they have successfully identified a critical datetime timezone bug:

```
Error calculating position: "can't subtract offset-naive and offset-aware datetimes"
```

This bug causes portfolio calculations to return `total_invested = 0.0` instead of correct values like `$21,000`.

### Test Coverage

```python
# Position calculations
test_simple_buy_position_calculation()      # Single buy transaction
test_multiple_buy_average_cost()           # Average cost calculation
test_buy_sell_position_calculation()       # Buy/sell scenarios

# Tax lot accounting (FIFO/LIFO)
test_fifo_tax_lot_calculation()           # First In, First Out
test_complex_tax_lot_scenario()           # Multiple buys and sells

# Edge cases
test_very_small_amounts()                 # Micro-investment amounts
test_very_large_amounts()                 # Large portfolio values
test_decimal_precision_in_calculations()  # Precision validation

# Multi-currency support
test_single_currency_portfolio()          # INR/USD calculations
test_multi_currency_calculations()        # Cross-currency scenarios
```

### Expected vs Actual Results

```python
# Example: Multiple buy average cost test
# Transactions:
# Buy 100 shares at $50.00 = $5,000
# Buy 200 shares at $60.00 = $12,000  
# Buy 100 shares at $40.00 = $4,000
# Expected: Total invested = $21,000, Average cost = $52.50
# Actual: Total invested = $0.0 (due to datetime bug)
```

---

## Known Issues & Workarounds

### 1. **Critical: Datetime Timezone Bug** üö®

**Issue**: Position calculations fail with timezone-aware vs timezone-naive datetime error

**Impact**: All portfolio calculations return 0.0 instead of correct values

**Root Cause**: `app/portfolio/positions.py` has datetime handling bug

**Status**: Identified by tests, needs fix

**Log Evidence**:
```
Error calculating position: "can't subtract offset-naive and offset-aware datetimes"
```

### 2. **Email Duplication in Tests** ‚úÖ **FIXED**

**Issue**: Test failures due to duplicate email addresses

**Solution**: Implemented timestamp + UUID based unique email generation

**Fix**:
```python
email = f"testuser_{int(time.time())}_{str(uuid.uuid4())[:8]}@example.com"
```

### 3. **Portfolio Model Field Mismatch** ‚úÖ **FIXED**

**Issue**: `base_currency` vs `currency` field confusion

**Solution**: Standardized on `base_currency` field in Portfolio model

### 4. **Invalid Portfolio ID Handling**

**Issue**: Upload API accepts invalid portfolio IDs (returns 200 instead of 400)

**Status**: Minor issue, needs validation improvement

**Expected**: Return 400/404 for invalid portfolio IDs

**Actual**: Returns 200 OK

---

## Best Practices

### 1. **Test Isolation**

Each test gets fresh data and database state:

```python
# Each test gets its own user to prevent conflicts
@pytest_asyncio.fixture
async def sample_user(db_session: AsyncSession) -> User:
    user_data = {
        "email": f"testuser_{int(time.time())}_{str(uuid.uuid4())[:8]}@example.com",
        # ... other fields
    }
```

### 2. **Realistic Test Data**

Use real-world data formats and values:

```python
# Real Vested CSV format
csv_content = """Date,Symbol,Company Name,Transaction Type,Quantity,Price,Total Amount
2024-01-15,AAPL,Apple Inc,BUY,100,150.25,15025.00"""
```

### 3. **Comprehensive Error Testing**

Test both happy path and error scenarios:

```python
# Success case
test_successful_upload()

# Error cases  
test_upload_empty_file()
test_upload_invalid_format()
test_upload_corrupted_data()
```

### 4. **Mathematical Precision**

Use Decimal for financial calculations:

```python
from decimal import Decimal

assert_decimal_equal(
    actual=Decimal("123.456"),
    expected=Decimal("123.46"), 
    tolerance=Decimal("0.01")
)
```

### 5. **Async Test Patterns**

Properly handle async operations:

```python
@pytest.mark.asyncio
async def test_async_operation(client: AsyncClient):
    response = await client.post("/api/endpoint", json=data)
    assert response.status_code == 200
```

---

## Troubleshooting

### Common Issues

#### 1. **Test Database Connection Issues**

```bash
# Check if SQLite is available
python -c "import sqlite3; print('SQLite OK')"

# Check async SQLite support
python -c "import aiosqlite; print('aiosqlite OK')"
```

#### 2. **Import Errors**

```bash
# Ensure you're in the correct directory
cd /Users/knandula/work/reaum

# Check Python path
python -c "import app; print('App imports OK')"
```

#### 3. **Async Event Loop Issues**

```python
# If you see event loop warnings, check pytest-asyncio configuration
# Add to pytest.ini:
[tool:pytest]
asyncio_mode = auto
```

#### 4. **Database Schema Issues**

```bash
# If tables aren't created, check alembic
alembic upgrade head

# Or recreate test database
python -c "
from tests.test_database import create_test_engine
from app.core.database import Base
import asyncio

async def create_tables():
    engine = create_test_engine()
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

asyncio.run(create_tables())
"
```

### Debugging Test Failures

#### 1. **Enable Detailed Logging**

```python
# In tests/test_database.py
def create_test_engine():
    return create_async_engine(
        database_url,
        echo=True,  # Enable SQL logging
        # ...
    )
```

#### 2. **Run Single Test with Debug Output**

```bash
python -m pytest tests/api/test_calculations.py::TestPositionCalculations::test_simple_buy_position_calculation -v -s --tb=long
```

#### 3. **Check Test Data**

```python
# Add debug prints in tests
print(f"User email: {sample_user.email}")
print(f"Portfolio ID: {sample_portfolio.id}")
print(f"Dashboard response: {dashboard_response.json()}")
```

---

## Test Results Summary

### Current Status (Latest Run)

```
========================= TEST RESULTS =========================
Total Tests: 79
Passed: 60 (76%)
Failed: 19 (24%)

Authentication Tests: 15/21 passing (71%)
Dashboard Tests: 6/6 passing (100%) ‚úÖ
Upload Tests: 20/21 passing (95%) ‚úÖ  
Calculation Tests: 0/17 passing (0%) - All failing due to datetime bug
Infrastructure Tests: Various minor issues

========================= FAILURE BREAKDOWN =========================
Critical Issues:
- Datetime timezone bug affecting all portfolio calculations
- Position calculations returning 0.0 instead of correct values

Minor Issues:  
- Email duplication (FIXED)
- Portfolio model field mismatch (FIXED)
- Invalid portfolio ID validation needed
- Test fixture assertion format mismatch
```

### Success Stories

1. **‚úÖ Upload System**: Vested CSV parsing working perfectly
2. **‚úÖ Authentication**: JWT token system functional  
3. **‚úÖ Dashboard API**: All endpoints working correctly
4. **‚úÖ Mathematical Validation**: Successfully catching critical bugs!
5. **‚úÖ Test Infrastructure**: Robust, isolated, repeatable

### Next Steps

1. **üö® Priority 1**: Fix datetime timezone bug in `app/portfolio/positions.py`
2. **üìã Priority 2**: Complete Reports API tests
3. **üîÑ Priority 3**: End-to-end workflow tests
4. **üêõ Priority 4**: Fix minor validation issues

---

## Contributing to Tests

### Adding New Tests

1. **Choose the right test file**:
   - `test_auth.py`: Authentication-related tests
   - `test_dashboard.py`: Dashboard and summary data tests  
   - `test_uploads.py`: File upload and parsing tests
   - `test_calculations.py`: Mathematical validation tests

2. **Follow naming conventions**:
   ```python
   class TestFeatureName:
       async def test_specific_behavior(self, fixtures...):
           """Clear description of what this test validates."""
   ```

3. **Use appropriate fixtures**:
   ```python
   async def test_new_feature(self, authenticated_user, sample_portfolio, client):
       headers = authenticated_user["headers"]
       # ... test implementation
   ```

4. **Include both success and failure cases**:
   ```python
   async def test_feature_success(self, ...):
       # Test happy path
   
   async def test_feature_validation_error(self, ...):  
       # Test error handling
   ```

### Test Quality Guidelines

1. **Clear test names**: Test name should describe what's being tested
2. **Single responsibility**: Each test should validate one specific behavior
3. **Realistic data**: Use real-world data formats and values
4. **Proper assertions**: Use specific assertions with clear error messages
5. **Clean fixtures**: Leverage existing fixtures, create new ones if needed

---

*Last Updated: November 2, 2025*
*Test Suite Version: 1.0*
*Documentation Maintained by: CapitalFlow Development Team*